pip install opencv-python numpy scikit-learn dlib face_recognition

import cv2
import face_recognition
import os

def extract_faces(image_path):
    image = cv2.imread(image_path)
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    face_locations = face_recognition.face_locations(rgb_image)
    face_encodings = face_recognition.face_encodings(rgb_image, face_locations)

    faces = []
    for (top, right, bottom, left), encoding in zip(face_locations, face_encodings):
        face_crop = image[top:bottom, left:right]
        faces.append((face_crop, encoding))
    
    return faces



def process_gallery(folder_path):
    profiles = []
    
    for filename in os.listdir(folder_path):
        if filename.endswith(('.jpg', '.png', '.jpeg')):
            faces = extract_faces(os.path.join(folder_path, filename))
            for face, encoding in faces:
                profiles.append((filename, face, encoding))
    
    return profiles



from sklearn.cluster import DBSCAN
import numpy as np

def cluster_faces(profiles, eps=0.5):
    encodings = np.array([profile[2] for profile in profiles])
    
    clustering = DBSCAN(eps=eps, min_samples=2, metric="euclidean").fit(encodings)
    
    clusters = {}
    for i, label in enumerate(clustering.labels_):
        if label == -1:
            continue  # Ignore noise
        
        if label not in clusters:
            clusters[label] = []
        
        clusters[label].append(profiles[i])
    
    return clusters


def display_profiles(clusters):
    for label, profiles in clusters.items():
        print(f"Profile {label}:")
        for filename, face, _ in profiles:
            cv2.imshow(f"Profile {label}", face)
            cv2.waitKey(1000)
            cv2.destroyAllWindows()



folder_path = "gallery_images"
profiles = process_gallery(folder_path)
clusters = cluster_faces(profiles, eps=0.5)
display_profiles(clusters)






===============================================================================================================================================






pip install tensorflow keras-facenet opencv-python numpy scikit-learn face-recognition


from keras_facenet import FaceNet

# Load FaceNet model
embedder = FaceNet()



import os
import numpy as np
import cv2

known_faces = {}  # Dictionary to store names and embeddings

def register_known_faces(folder_path):
    for filename in os.listdir(folder_path):
        if filename.endswith(('.jpg', '.png', '.jpeg')):
            name = os.path.splitext(filename)[0]  # Extract name from file
            image_path = os.path.join(folder_path, filename)
            
            image = cv2.imread(image_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # Generate embedding using FaceNet
            embedding = embedder.embeddings([image])[0]
            known_faces[name] = embedding

register_known_faces("known_faces")  # Folder with labeled images




from sklearn.metrics.pairwise import cosine_similarity

def recognize_face(embedding):
    best_match = None
    highest_similarity = 0.0

    for name, known_embedding in known_faces.items():
        similarity = cosine_similarity([embedding], [known_embedding])[0][0]

        if similarity > 0.5 and similarity > highest_similarity:  # Adjust threshold if needed
            highest_similarity = similarity
            best_match = name
    
    return best_match if best_match else "Unknown"




def cluster_and_recognize(profiles, eps=0.5):
    encodings = np.array([profile[2] for profile in profiles])
    
    clustering = DBSCAN(eps=eps, min_samples=2, metric="euclidean").fit(encodings)
    
    clusters = {}
    for i, label in enumerate(clustering.labels_):
        if label == -1:
            continue  # Ignore noise
        
        if label not in clusters:
            clusters[label] = []
        
        name = recognize_face(profiles[i][2])  # Identify name
        clusters[label].append((name, profiles[i][0], profiles[i][1]))
    
    return clusters



def display_named_profiles(clusters):
    for label, profiles in clusters.items():
        print(f"Profile {label} - {profiles[0][0]}:")
        for name, filename, face in profiles:
            cv2.imshow(f"{name} - Profile {label}", face)
            cv2.waitKey(1000)
            cv2.destroyAllWindows()



folder_path = "gallery_images"
profiles = process_gallery(folder_path)
clusters = cluster_and_recognize(profiles, eps=0.5)
display_named_profiles(clusters)



==========================================================================================================================================


pip install fastapi uvicorn opencv-python numpy moviepy python-multipart


import cv2
import numpy as np
import shutil
import uvicorn
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import FileResponse
from ultralytics import YOLO  # Assuming YOLO is being used
import tempfile
import os

app = FastAPI()

# Load the object detection model
model = YOLO("yolov8n.pt")  # Change to your model

def process_video(input_path, output_path):
    cap = cv2.VideoCapture(input_path)
    
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        results = model(frame)

        for r in results:
            boxes = r.boxes
            for box in boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                conf = box.conf[0].item()
                cls = int(box.cls[0].item())

                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f"{model.names[cls]} {conf:.2f}", 
                            (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX,
                            0.5, (0, 255, 0), 2)

        out.write(frame)

    cap.release()
    out.release()

@app.post("/upload_video/")
async def upload_video(file: UploadFile = File(...)):
    # Save uploaded file to a temporary directory
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_video:
        shutil.copyfileobj(file.file, temp_video)
        temp_video_path = temp_video.name

    output_video_path = temp_video_path.replace(".mp4", "_output.mp4")
    
    # Process video with object detection
    process_video(temp_video_path, output_video_path)

    # Return processed video
    return FileResponse(output_video_path, media_type="video/mp4", filename="processed_video.mp4")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)




Please complete the Assignment before 4 PM tomorrow and share it with me in PDF format.

Attached is a sample data file. 74368 rows of anonymized Data, set for the year 2052 for test purposes.

Question - 1

Test_Data_analysis.xlsx

Can you prepare an analysis on a google spreadsheet and answer the following questions through data views -

Which sleep phase (REM or Deep) shows higher variability across users? Please explain through data.
What is the average steps done - classified by sleep mid-point for different users.
How does stress levels vary based on early sleepers, late sleepers ( you can assume cutoff for early and late sleep.
Which weekday had most average sleep recorded.
Which user_id sleeps most and which user_id sleeps least.
Question-2

You are given a table named luna_daily_metrics with the following schema:

luna_daily_metrics (

user_id BIGINT,

date DATE, 

circadian_midpoint TIME, 

avg_heart_rate INTEGER,

master_avg_hrv INTEGER, 

master_duration INTEGER,
master_rem INTEGER, 

master_deep INTEGER, 

total_steps INTEGER, 

total_calories INTEGER, 

active_calories INTEGER, 

stress_value INTEGER, 

workout_count INTEGER 

)

Write a SQL query to identify the top 5 users with the highest average HRV over the past 7 days, only considering users who worked out at least 3 times in that period.



