{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=95\n",
    "TRIALS=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import glob\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor, VotingRegressor, RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import warnings\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T03:49:13.193149Z",
     "iopub.status.busy": "2025-02-14T03:49:13.192822Z",
     "iopub.status.idle": "2025-02-14T03:49:51.835788Z",
     "shell.execute_reply": "2025-02-14T03:49:51.83451Z",
     "shell.execute_reply.started": "2025-02-14T03:49:13.193123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path = 'march-machine-learning-mania-2025/**'\n",
    "data = {p.split('/')[-1].split('.')[0].split('\\\\')[-1] : pd.read_csv(p, encoding='latin-1') for p in glob.glob(path)}\n",
    "teams = pd.concat([data['MTeams'], data['WTeams']])\n",
    "teams_spelling = pd.concat([data['MTeamSpellings'], data['WTeamSpellings']])\n",
    "teams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\n",
    "teams_spelling.columns = ['TeamID', 'TeamNameCount']\n",
    "teams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n",
    "del teams_spelling\n",
    "\n",
    "season_cresults = pd.concat([data['MRegularSeasonCompactResults'], data['WRegularSeasonCompactResults']])\n",
    "season_dresults = pd.concat([data['MRegularSeasonDetailedResults'], data['WRegularSeasonDetailedResults']])\n",
    "tourney_cresults = pd.concat([data['MNCAATourneyCompactResults'], data['WNCAATourneyCompactResults']])\n",
    "tourney_dresults = pd.concat([data['MNCAATourneyDetailedResults'], data['WNCAATourneyDetailedResults']])\n",
    "slots = pd.concat([data['MNCAATourneySlots'], data['WNCAATourneySlots']])\n",
    "seeds = pd.concat([data['MNCAATourneySeeds'], data['WNCAATourneySeeds']])\n",
    "gcities = pd.concat([data['MGameCities'], data['WGameCities']])\n",
    "seasons = pd.concat([data['MSeasons'], data['WSeasons']])\n",
    "\n",
    "seeds = {'_'.join(map(str,[int(k1),k2])):int(v[1:3]) for k1, v, k2 in seeds[['Season', 'Seed', 'TeamID']].values}\n",
    "cities = data['Cities']\n",
    "sub = data['SampleSubmissionStage1']\n",
    "del data\n",
    "\n",
    "season_cresults['ST'] = 'S'\n",
    "season_dresults['ST'] = 'S'\n",
    "tourney_cresults['ST'] = 'T'\n",
    "tourney_dresults['ST'] = 'T'\n",
    "#games = pd.concat((season_cresults, tourney_cresults), axis=0, ignore_index=True)\n",
    "games = pd.concat((season_dresults, tourney_dresults), axis=0, ignore_index=True)\n",
    "games.reset_index(drop=True, inplace=True)\n",
    "games['WLoc'] = games['WLoc'].map({'A': 1, 'H': 2, 'N': 3})\n",
    "\n",
    "games['ID'] = games.apply(lambda r: '_'.join(map(str, [r['Season']]+sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "games['IDTeams'] = games.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
    "games['Team1'] = games.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[0], axis=1)\n",
    "games['Team2'] = games.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[1], axis=1)\n",
    "games['IDTeam1'] = games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "games['IDTeam2'] = games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "\n",
    "games['Team1Seed'] = games['IDTeam1'].map(seeds).fillna(0)\n",
    "games['Team2Seed'] = games['IDTeam2'].map(seeds).fillna(0)\n",
    "\n",
    "games['ScoreDiff'] = games['WScore'] - games['LScore']\n",
    "games['Pred'] = games.apply(lambda r: 1. if sorted([r['WTeamID'],r['LTeamID']])[0]==r['WTeamID'] else 0., axis=1)\n",
    "games['ScoreDiffNorm'] = games.apply(lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0. else r['ScoreDiff'], axis=1)\n",
    "games['SeedDiff'] = games['Team1Seed'] - games['Team2Seed']\n",
    "games = games.fillna(-1)\n",
    "\n",
    "c_score_col = ['NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl',\n",
    " 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl',\n",
    " 'LBlk', 'LPF']\n",
    "c_score_agg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\n",
    "gb = games.groupby(by=['IDTeams']).agg({k: c_score_agg for k in c_score_col}).reset_index()\n",
    "gb.columns = [''.join(c) + '_c_score' for c in gb.columns]\n",
    "\n",
    "games = games[games['ST']=='T']\n",
    "\n",
    "sub['WLoc'] = 3\n",
    "sub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\n",
    "sub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\n",
    "sub['Season'] = sub['Season'].astype(int)\n",
    "sub['Team1'] = sub['ID'].map(lambda x: x.split('_')[1])\n",
    "sub['Team2'] = sub['ID'].map(lambda x: x.split('_')[2])\n",
    "sub['IDTeams'] = sub.apply(lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1)\n",
    "sub['IDTeam1'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "sub['IDTeam2'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "sub['Team1Seed'] = sub['IDTeam1'].map(seeds).fillna(0)\n",
    "sub['Team2Seed'] = sub['IDTeam2'].map(seeds).fillna(0)\n",
    "sub['SeedDiff'] = sub['Team1Seed'] - sub['Team2Seed']\n",
    "sub = sub.fillna(-1)\n",
    "\n",
    "games = pd.merge(games, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "sub = pd.merge(sub, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
    "\n",
    "col = [c for c in games.columns if c not in ['ID', 'DayNum', 'ST', 'Team1', 'Team2', 'IDTeams', 'IDTeam1', 'IDTeam2', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'NumOT', 'Pred', 'ScoreDiff', 'ScoreDiffNorm', 'WLoc'] + c_score_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T03:50:14.478276Z",
     "iopub.status.busy": "2025-02-14T03:50:14.47792Z",
     "iopub.status.idle": "2025-02-14T03:50:37.211121Z",
     "shell.execute_reply": "2025-02-14T03:50:37.210245Z",
     "shell.execute_reply.started": "2025-02-14T03:50:14.478245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = games[col].fillna(-1)\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "sub_X = sub[col].fillna(-1)\n",
    "sub_X_imputed = imputer.transform(sub_X)\n",
    "sub_X_scaled = scaler.transform(sub_X_imputed)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"scaled_data.npz\")\n",
    "X_scaled = data[\"X_scaled\"]\n",
    "sub_X_scaled = data[\"sub_X_scaled\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    et_params = {\n",
    "        'n_estimators': trial.suggest_int('et_n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('et_max_depth', 5, 30),\n",
    "        'min_samples_split': trial.suggest_int('et_min_samples_split', 2, 10),\n",
    "        'max_features': trial.suggest_categorical('et_max_features', ['sqrt', 'log2', None]),\n",
    "        'criterion': trial.suggest_categorical('et_criterion', ['squared_error', 'absolute_error']),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': SEED,\n",
    "        'verbose':False\n",
    "    }\n",
    "    rf_params = {\n",
    "        'n_estimators': trial.suggest_int('rf_n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('rf_max_depth', 5, 30),\n",
    "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 10),\n",
    "        'max_features': trial.suggest_categorical('rf_max_features', ['sqrt', 'log2', None]),\n",
    "        'bootstrap': trial.suggest_categorical('rf_bootstrap', [True, False]),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': SEED,\n",
    "        'verbose':False\n",
    "    }\n",
    "    lgb_params = {\n",
    "        'n_estimators': trial.suggest_int('lgb_n_estimators', 100, 500),\n",
    "        'num_leaves': trial.suggest_int('lgb_num_leaves', 20, 300),\n",
    "        'learning_rate': trial.suggest_float('lgb_learning_rate', 0.01, 0.3, log=True),\n",
    "        'boosting_type': trial.suggest_categorical('lgb_boosting_type', ['gbdt', 'dart']),\n",
    "        'random_state': SEED,\n",
    "        'verbose':-1\n",
    "    }\n",
    "    xgb_params = {\n",
    "        'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('xgb_max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('xgb_subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.5, 1.0),\n",
    "        'random_state': SEED,\n",
    "        'verbose':-1\n",
    "    }\n",
    "    \n",
    "    et = ExtraTreesRegressor(**et_params)\n",
    "    rf = RandomForestRegressor(**rf_params)\n",
    "    lgb = LGBMRegressor(**lgb_params)\n",
    "    xgb = XGBRegressor(**xgb_params)\n",
    "    \n",
    "    voting_regressor = VotingRegressor(estimators=[('et', et), ('rf', rf), ('lgb', lgb), ('xgb', xgb)])\n",
    "    model = Pipeline(steps=[\n",
    "        ('voting', voting_regressor)\n",
    "    ])\n",
    "    \n",
    "    model.fit(X_scaled, games['Pred'])\n",
    "    cv_scores = cross_val_score(model, X_scaled, games['Pred'], cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    print(f\"Trial {trial.number} parameters: {trial.params}\")\n",
    "    return -cv_scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study.optimize(objective, n_trials=TRIALS, show_progress_bar=True)\n",
    "\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-14T03:50:37.254869Z",
     "iopub.status.busy": "2025-02-14T03:50:37.254594Z",
     "iopub.status.idle": "2025-02-14T03:51:04.99243Z",
     "shell.execute_reply": "2025-02-14T03:51:04.991503Z",
     "shell.execute_reply.started": "2025-02-14T03:50:37.254847Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_params={'et_n_estimators': 119, 'et_max_depth': 5, 'et_min_samples_split': 5, 'et_max_features': None, 'et_criterion': 'squared_error', 'rf_n_estimators': 245, 'rf_max_depth': 8, 'rf_min_samples_split': 2, 'rf_max_features': 'sqrt', 'rf_bootstrap': False, 'lgb_n_estimators': 261, 'lgb_num_leaves': 299, 'lgb_learning_rate': 0.011503013718176918, 'lgb_boosting_type': 'gbdt', 'xgb_n_estimators': 261, 'xgb_max_depth': 3, 'xgb_learning_rate': 0.0107609632482878, 'xgb_subsample': 0.7755691972978731, 'xgb_colsample_bytree': 0.778710574834427}\n",
    "\n",
    "rf_best_params = {k.replace('rf__', ''): v for k, v in best_params.items() if k.startswith('rf__')}\n",
    "et_best_params = {k.replace('et__', ''): v for k, v in best_params.items() if k.startswith('et__')}\n",
    "lgb_best_params = {k.replace('lgb__', ''): v for k, v in best_params.items() if k.startswith('lgb__')}\n",
    "xgb_best_params = {k.replace('xgb__', ''): v for k, v in best_params.items() if k.startswith('xgb__')}\n",
    "\n",
    "et = ExtraTreesRegressor(**et_best_params)\n",
    "rf = RandomForestRegressor(**rf_best_params)\n",
    "lgb = LGBMRegressor(**lgb_best_params)\n",
    "xgb = XGBRegressor(**xgb_best_params)\n",
    "voting_regressor = VotingRegressor(estimators=[('et', et), ('rf', rf), ('lgb', lgb), ('xgb', xgb)])\n",
    "pipe = Pipeline(steps=[\n",
    "        ('voting', voting_regressor)\n",
    "    ])\n",
    "pipe.fit(X_scaled, games['Pred'])\n",
    "pred = pipe.predict(sub_X_scaled).clip(0.001, 0.999)\n",
    "train_pred = pipe.predict(X_scaled).clip(0.001, 0.999)\n",
    "ir = IsotonicRegression(out_of_bounds='clip')\n",
    "ir.fit(train_pred, games['Pred'])\n",
    "sub['Pred'] = ir.transform(pred)\n",
    "\n",
    "sub[['ID', 'Pred']].to_csv('submission.csv', index=False)\n",
    "print(sub[['ID', 'Pred']].head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11018643,
     "sourceId": 91497,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
