{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install optuna"
      ],
      "metadata": {
        "id": "8ztDW6kAf5rU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qj1QfqAPOThb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import *\n",
        "import glob\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import ExtraTreesRegressor, VotingRegressor, RandomForestRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import warnings\n",
        "import optuna\n",
        "from sklearn.isotonic import IsotonicRegression\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'data/**'\n",
        "data = {p.split('/')[-1].split('.')[0].split('\\\\')[-1] : pd.read_csv(p, encoding='latin-1') for p in glob.glob(path)}\n",
        "teams = pd.concat([data['MTeams'], data['WTeams']])\n",
        "teams_spelling = pd.concat([data['MTeamSpellings'], data['WTeamSpellings']])\n",
        "teams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\n",
        "teams_spelling.columns = ['TeamID', 'TeamNameCount']\n",
        "teams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n",
        "del teams_spelling\n",
        "\n",
        "season_cresults = pd.concat([data['MRegularSeasonCompactResults'], data['WRegularSeasonCompactResults']])\n",
        "season_dresults = pd.concat([data['MRegularSeasonDetailedResults'], data['WRegularSeasonDetailedResults']])\n",
        "tourney_cresults = pd.concat([data['MNCAATourneyCompactResults'], data['WNCAATourneyCompactResults']])\n",
        "tourney_dresults = pd.concat([data['MNCAATourneyDetailedResults'], data['WNCAATourneyDetailedResults']])\n",
        "slots = pd.concat([data['MNCAATourneySlots'], data['WNCAATourneySlots']])\n",
        "seeds = pd.concat([data['MNCAATourneySeeds'], data['WNCAATourneySeeds']])\n",
        "gcities = pd.concat([data['MGameCities'], data['WGameCities']])\n",
        "seasons = pd.concat([data['MSeasons'], data['WSeasons']])\n",
        "\n",
        "seeds = {'_'.join(map(str,[int(k1),k2])):int(v[1:3]) for k1, v, k2 in seeds[['Season', 'Seed', 'TeamID']].values}\n",
        "cities = data['Cities']\n",
        "sub = data['SampleSubmissionStage1']\n",
        "del data\n",
        "\n",
        "season_cresults['ST'] = 'S'\n",
        "season_dresults['ST'] = 'S'\n",
        "tourney_cresults['ST'] = 'T'\n",
        "tourney_dresults['ST'] = 'T'\n",
        "#games = pd.concat((season_cresults, tourney_cresults), axis=0, ignore_index=True)\n",
        "games = pd.concat((season_dresults, tourney_dresults), axis=0, ignore_index=True)\n",
        "games.reset_index(drop=True, inplace=True)\n",
        "games['WLoc'] = games['WLoc'].map({'A': 1, 'H': 2, 'N': 3})\n",
        "\n",
        "games['ID'] = games.apply(lambda r: '_'.join(map(str, [r['Season']]+sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
        "games['IDTeams'] = games.apply(lambda r: '_'.join(map(str, sorted([r['WTeamID'],r['LTeamID']]))), axis=1)\n",
        "games['Team1'] = games.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[0], axis=1)\n",
        "games['Team2'] = games.apply(lambda r: sorted([r['WTeamID'],r['LTeamID']])[1], axis=1)\n",
        "games['IDTeam1'] = games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
        "games['IDTeam2'] = games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
        "\n",
        "games['Team1Seed'] = games['IDTeam1'].map(seeds).fillna(0)\n",
        "games['Team2Seed'] = games['IDTeam2'].map(seeds).fillna(0)\n",
        "\n",
        "games['ScoreDiff'] = games['WScore'] - games['LScore']\n",
        "games['Pred'] = games.apply(lambda r: 1. if sorted([r['WTeamID'],r['LTeamID']])[0]==r['WTeamID'] else 0., axis=1)\n",
        "games['ScoreDiffNorm'] = games.apply(lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0. else r['ScoreDiff'], axis=1)\n",
        "games['SeedDiff'] = games['Team1Seed'] - games['Team2Seed']\n",
        "games = games.fillna(-1)\n",
        "\n",
        "c_score_col = ['NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl',\n",
        " 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl',\n",
        " 'LBlk', 'LPF']\n",
        "c_score_agg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\n",
        "gb = games.groupby(by=['IDTeams']).agg({k: c_score_agg for k in c_score_col}).reset_index()\n",
        "gb.columns = [''.join(c) + '_c_score' for c in gb.columns]\n",
        "\n",
        "games = games[games['ST']=='T']\n",
        "\n",
        "sub['WLoc'] = 3\n",
        "sub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\n",
        "sub['Season'] = sub['ID'].map(lambda x: x.split('_')[0])\n",
        "sub['Season'] = sub['Season'].astype(int)\n",
        "sub['Team1'] = sub['ID'].map(lambda x: x.split('_')[1])\n",
        "sub['Team2'] = sub['ID'].map(lambda x: x.split('_')[2])\n",
        "sub['IDTeams'] = sub.apply(lambda r: '_'.join(map(str, [r['Team1'], r['Team2']])), axis=1)\n",
        "sub['IDTeam1'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
        "sub['IDTeam2'] = sub.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
        "sub['Team1Seed'] = sub['IDTeam1'].map(seeds).fillna(0)\n",
        "sub['Team2Seed'] = sub['IDTeam2'].map(seeds).fillna(0)\n",
        "sub['SeedDiff'] = sub['Team1Seed'] - sub['Team2Seed']\n",
        "sub = sub.fillna(-1)\n",
        "\n",
        "games = pd.merge(games, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
        "sub = pd.merge(sub, gb, how='left', left_on='IDTeams', right_on='IDTeams_c_score')\n",
        "\n",
        "col = [c for c in games.columns if c not in ['ID', 'DayNum', 'ST', 'Team1', 'Team2', 'IDTeams', 'IDTeam1', 'IDTeam2', 'WTeamID', 'WScore', 'LTeamID', 'LScore', 'NumOT', 'Pred', 'ScoreDiff', 'ScoreDiffNorm', 'WLoc'] + c_score_col]"
      ],
      "metadata": {
        "id": "rPoACzUTOni5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=32)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_imputed = imputer.fit_transform(games[col])\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "sub_X_imputed = imputer.transform(sub[col])\n",
        "sub_X_scaled = scaler.transform(sub_X_imputed)\n",
        "\n",
        "np.savez_compressed(\"scaled_data.npz\", X_scaled=X_scaled, sub_X_scaled=sub_X_scaled)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "wuHER0iVO7j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "games[\"Pred\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "hccmEyv2rbIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez_compressed(\"scaled_data.npz\", X_scaled=X_scaled, sub_X_scaled=sub_X_scaled)"
      ],
      "metadata": {
        "id": "Zx0w8fPZpvfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load(\"scaled_data.npz\")\n",
        "X_scaled = data[\"X_scaled\"]\n",
        "sub_X_scaled = data[\"sub_X_scaled\"]"
      ],
      "metadata": {
        "id": "KT8ECSEcpyLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED=95"
      ],
      "metadata": {
        "id": "rxE88GDqhyEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(trial):\n",
        "    rf_params = {\n",
        "        'n_estimators': trial.suggest_int('rf_n_estimators', 200, 400),\n",
        "        'max_depth': trial.suggest_int('rf_max_depth', 5, 30),\n",
        "        'min_samples_split': trial.suggest_int('rf_min_samples_split', 2, 10),\n",
        "        'max_features': trial.suggest_categorical('rf_max_features', ['sqrt', 'log2', None]),\n",
        "        'bootstrap': trial.suggest_categorical('rf_bootstrap', [True, False]),\n",
        "        'random_state': SEED\n",
        "    }\n",
        "\n",
        "    xgb_params = {\n",
        "        'n_estimators': trial.suggest_int('xgb_n_estimators', 200, 400),\n",
        "        'max_depth': trial.suggest_int('xgb_max_depth', 3, 15),\n",
        "        'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.3, log=True),\n",
        "        'subsample': trial.suggest_float('xgb_subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('xgb_colsample_bytree', 0.5, 1.0),\n",
        "        'random_state': SEED\n",
        "    }\n",
        "\n",
        "    et_params = {\n",
        "        'n_estimators': trial.suggest_int('et_n_estimators', 200, 400),\n",
        "        'max_depth': trial.suggest_int('et_max_depth', 5, 30),\n",
        "        'min_samples_split': trial.suggest_int('et_min_samples_split', 2, 10),\n",
        "        'max_features': trial.suggest_categorical('et_max_features', ['sqrt', 'log2', None]),\n",
        "        'random_state': SEED\n",
        "    }\n",
        "\n",
        "    lgb_params = {\n",
        "        'n_estimators': trial.suggest_int('lgb_n_estimators', 200, 400),\n",
        "        'num_leaves': trial.suggest_int('lgb_num_leaves', 20, 300),\n",
        "        'learning_rate': trial.suggest_float('lgb_learning_rate', 0.01, 0.3, log=True),\n",
        "        'boosting_type': trial.suggest_categorical('lgb_boosting_type', ['gbdt', 'dart']),\n",
        "        'random_state': SEED\n",
        "    }\n",
        "\n",
        "\n",
        "    rf = RandomForestClassifier(**rf_params,verbose=False)\n",
        "    xgb = XGBClassifier(**xgb_params,verbose=False)\n",
        "    et = ExtraTreesClassifier(**et_params,verbose=False)\n",
        "    lgb = LGBMClassifier(**lgb_params,verbose=False)\n",
        "\n",
        "    voting_clf = VotingClassifier(\n",
        "        estimators=[('rf', rf), ('xgb', xgb), ('et', et), ('lgb', lgb)],\n",
        "        voting='soft'\n",
        "    )\n",
        "\n",
        "    model = Pipeline(steps=[('voting', voting_clf)])\n",
        "    cv_scores = cross_val_score(model, X, y, cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
        "    print(f\"Trial {trial.number} parameters: {trial.params}\")\n",
        "    return -cv_scores.mean()\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
        "print(\"Best Parameters:\")\n",
        "print(study.best_params)"
      ],
      "metadata": {
        "id": "_ztWjojaO-FE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = {}\n",
        "\n",
        "rf_best_params = {k.replace('rf__', ''): v for k, v in best_params.items() if k.startswith('rf__')}\n",
        "et_best_params = {k.replace('et__', ''): v for k, v in best_params.items() if k.startswith('et__')}\n",
        "lgb_best_params = {k.replace('lgb__', ''): v for k, v in best_params.items() if k.startswith('lgb__')}\n",
        "xgb_best_params = {k.replace('xgb__', ''): v for k, v in best_params.items() if k.startswith('xgb__')}\n",
        "\n",
        "et = ExtraTreesClassifier(**et_best_params,verbose=False)\n",
        "rf = RandomForestClassifier(**rf_best_params,verbose=False)\n",
        "lgb = LGBMClassifier(**lgb_best_params,verbose=False)\n",
        "xgb = XGBClassifier(**xgb_best_params,verbose=False)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('et', et), ('rf', rf), ('lgb', lgb), ('xgb', xgb)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "pipe = Pipeline(steps=[('voting', voting_clf)])\n",
        "\n",
        "pipe.fit(X_scaled, games['Pred'])\n",
        "sub['Pred'] = pipe.predict(sub_X_scaled)\n",
        "sub[['ID', 'Pred']].to_csv('submission.csv', index=False)\n",
        "print(sub[['ID', 'Pred']].head())"
      ],
      "metadata": {
        "id": "nCeoui0qoaxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params={}\n",
        "\n",
        "rf_best_params = {k.replace('rf__', ''): v for k, v in best_params.items() if k.startswith('rf__')}\n",
        "et_best_params = {k.replace('et__', ''): v for k, v in best_params.items() if k.startswith('et__')}\n",
        "lgb_best_params = {k.replace('lgb__', ''): v for k, v in best_params.items() if k.startswith('lgb__')}\n",
        "xgb_best_params = {k.replace('xgb__', ''): v for k, v in best_params.items() if k.startswith('xgb__')}\n",
        "\n",
        "et = ExtraTreesRegressor(**et_best_params)\n",
        "rf = RandomForestRegressor(**rf_best_params)\n",
        "lgb = LGBMRegressor(**lgb_best_params)\n",
        "xgb = XGBRegressor(**xgb_best_params)\n",
        "voting_regressor = VotingRegressor(estimators=[('et', et), ('rf', rf), ('lgb', lgb), ('xgb', xgb)])\n",
        "pipe = Pipeline(steps=[\n",
        "        ('voting', voting_regressor)\n",
        "    ])\n",
        "pipe.fit(X_scaled, games['Pred'])\n",
        "pred = int(pipe.predict(sub_X_scaled)).clip(0.001, 0.999)\n",
        "train_pred = int(pipe.predict(X_scaled)).clip(0.001, 0.999)\n",
        "ir = IsotonicRegression(out_of_bounds='clip')\n",
        "ir.fit(train_pred, games['Pred'])\n",
        "sub['Pred'] = ir.transform(pred)\n",
        "\n",
        "sub[['ID', 'Pred']].to_csv('submission.csv', index=False)\n",
        "print(sub[['ID', 'Pred']].head())"
      ],
      "metadata": {
        "id": "bTrY3jLshrx4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}